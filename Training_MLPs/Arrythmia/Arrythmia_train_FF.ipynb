{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b710481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "seed=0\n",
    "np.random.seed(seed)\n",
    "\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "import tensorflow.compat.v1 as tf1\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "from qkeras.utils import model_save_quantized_weights, load_qmodel\n",
    "import hls4ml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9492f417",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c6d5cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       8\n",
      "1       6\n",
      "2      10\n",
      "3       1\n",
      "4       7\n",
      "       ..\n",
      "447     1\n",
      "448    10\n",
      "449     2\n",
      "450     1\n",
      "451     1\n",
      "Name: Y, Length: 452, dtype: int64\n",
      "[ 1  2  3  4  5  6  7  8  9 10 14 15 16]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./arrhythmia.csv', sep = ',')\n",
    "df=df.dropna(axis=1)\n",
    "X = df.drop('Y', axis = 1).values\n",
    "y = df.Y\n",
    "le = LabelEncoder()\n",
    "print(y)\n",
    "y = le.fit_transform(y)\n",
    "print(le.classes_)\n",
    "y = to_categorical(y, 16)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acaf8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "ls=np.argmax(Y_test,axis=1)\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2b998c",
   "metadata": {},
   "source": [
    "# Create model with random sizes of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83cf45fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 20\n",
    "id_num = 2\n",
    "max_RF = 100\n",
    "models=[]\n",
    "first_layer=[]\n",
    "second_layer=[]\n",
    "layers = np.arange(1,21)\n",
    "bits = 8\n",
    "int_bits = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6333d1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(model_num):\n",
    "    input1 = 274\n",
    "    layer1 = layers[i]\n",
    "    first_layer.append(layer1)\n",
    "    output1 = 16\n",
    "    print(\"Model number \"+ str(i))\n",
    "    print(\"Input size: \" + str(input1))\n",
    "    print(\"First layer: \"+ str(layer1))\n",
    "    print(\"Output size: \" + str(output1))\n",
    "    print(\"-----------------\")\n",
    "    model=Sequential()\n",
    "    model.add(QDense(layer1, input_shape=(input1,), name='fc1', kernel_quantizer=quantized_bits(bits,int_bits,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(bits,int_bits,alpha=1),\n",
    "                    kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ))\n",
    "    model.add(QActivation(activation=quantized_relu(bits,int_bits,use_stochastic_rounding=False), name='relu1'))\n",
    "    model.add(QDense(output1, name='output',\n",
    "                    kernel_quantizer=quantized_bits(bits,int_bits,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(bits,int_bits,alpha=1),\n",
    "                    kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "    model.add(Activation(activation='softmax', name='softmax'))\n",
    "    models.append(model)\n",
    "\n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20242ffc",
   "metadata": {},
   "source": [
    "## Train models and synthesize HLS models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "114d3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_num = 3\n",
    "dirname = './models/models_' + str(id_num) + \"/prec_8/model_\"\n",
    "dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d98821b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### load pre trained models ########\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "import qkeras.qtools.qtools_util\n",
    "import qkeras.estimate\n",
    "loaded_models = []\n",
    "for model_no in range(model_num):\n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    loaded_models.append(load_model(dirname + str(model_no) + '/KERAS_check_best_model.h5', custom_objects=co))\n",
    "#model = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71443437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "Train = True\n",
    "selector = 0\n",
    "for precision in range(8,1,-1):\n",
    "    x = 0\n",
    "    dirname = './models/models_' + str(id_num) + \"/prec_\" + str(precision) + \"/model_\"\n",
    "    for i in range(x,model_num,1):    \n",
    "        adam = Adam(lr=0.02)\n",
    "        if(Train):\n",
    "            pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(0.2, begin_step=2000, frequency=100)}\n",
    "            models[i] = prune.prune_low_magnitude(models[i], **pruning_params)\n",
    "            models[i].compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "            callbacks= all_callbacks( outputDir = 'arrythmia_classification_prune_new')\n",
    "            callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "\n",
    "            models[i].fit(X_train,Y_train,batch_size=64,epochs=10,\n",
    "                validation_split=0.25,\n",
    "                verbose=1,\n",
    "                shuffle=True,\n",
    "                callbacks=callbacks.callbacks,\n",
    "                )\n",
    "            models[i] = strip_pruning(models[i])\n",
    "            models[i].save(dirname + str(i) + '/KERAS_check_best_model.h5')\n",
    "\n",
    "        rf_range = [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100]\n",
    "        for j in rf_range:for j in rf_range:\n",
    "            config = hls4ml.utils.config_from_keras_model(loaded_models[i],granularity='name')\n",
    "\n",
    "            config['LayerName']['fc1_input']['Precision']['result'] = 'fixed<' + str(precision) + ',2>'\n",
    "            config['LayerName']['relu1']['Precision']['result'] = 'ap_ufixed<' + str(precision) + ',0,AP_RND_CONV,AP_SAT>'\n",
    "            \n",
    "            config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "            config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "            config['Model']['ReuseFactor'] = j + 1\n",
    "\n",
    "\n",
    "            hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "                loaded_models[i],hls_config = config,output_dir = dirname + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj',part = 'xc7z007s-clg225-2')\n",
    "            hls_model.compile()\n",
    "            os.system('cp -r build_prj_orig.tcl project_orig.tcl build_prj_orig_lut.tcl ' + dirname + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj')\n",
    "            os.system('cp init.sh init_lut.sh ' + dirname + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj')\n",
    "            start_dir = os.getcwd()\n",
    "            os.chdir(r'./models/models_'+ str(id_num) + \"/prec_\" + str(precision) + \"/model_\" + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj')\n",
    "            if selector:\n",
    "                os.system('bash init.sh')\n",
    "                os.system('rm init_lut.sh')\n",
    "            else:\n",
    "                os.system('rm init.sh')\n",
    "                os.system('bash init_lut.sh')\n",
    "            os.chdir(start_dir)        \n",
    "            if j==9:\n",
    "                     for num in range(j+2):\n",
    "                         os.system('rm -r ' + dirname +str(i) + '/reuse_' + str(num) + '/hls4ml_prj/myproject_prj/solution1/.autopilot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa02013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
