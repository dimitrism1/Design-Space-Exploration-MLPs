{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70887ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 19:55:25.116611: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-23 19:55:25.213931: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-23 19:55:27.260645: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-09-23 19:55:27.260675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: skylla\n",
      "2024-09-23 19:55:27.260679: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: skylla\n",
      "2024-09-23 19:55:27.260808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.183.1\n",
      "2024-09-23 19:55:27.260824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.183.1\n",
      "2024-09-23 19:55:27.260827: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.183.1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "import os\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "import tensorflow.compat.v1 as tf1\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "tf.config.set_visible_devices([], 'GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dbd84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./breast-cancer-wisconsin.csv', sep = ';')\n",
    "X = df.drop('Y', axis = 1).values\n",
    "y = df.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a0219dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "Y_reshaped = [[label] for label in y]\n",
    "Y_encoded = encoder.fit_transform(Y_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96092f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_encoded = Y_encoded.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d004507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y_encoded,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99aafd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler(feature_range=(0,0.9))\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de0aee",
   "metadata": {},
   "source": [
    "# Train for different precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35e196da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/models_0/prec_8/model_'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_num = 20\n",
    "id_num = 0\n",
    "max_RF = 100\n",
    "precision = 8\n",
    "dirname = './models/models_' + str(id_num) + \"/prec_\" + str(precision) + \"/model_\"\n",
    "dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d78843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitsas/anaconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/hls4ml/converters/__init__.py:27: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "from qkeras.utils import model_save_quantized_weights, load_qmodel\n",
    "import hls4ml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c693ef8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 13:26:59.565280: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dmitsas/anaconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dmitsas/anaconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "import qkeras.qtools.qtools_util\n",
    "import qkeras.estimate\n",
    "loaded_models = []\n",
    "for model_no in range(model_num):\n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    loaded_models.append(load_model(dirname + str(model_no) + '/KERAS_check_best_model.h5', custom_objects=co))\n",
    "#model = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d15ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready = False\n",
    "models = []\n",
    "first_layer = []\n",
    "sec_layer = []\n",
    "model_num = 20\n",
    "model_layers = [[] for x in range(model_num)]\n",
    "bits = 8\n",
    "int_bits = 0\n",
    "for i in range(model_num):\n",
    "    if ready:\n",
    "        input1 = 10\n",
    "        layer1 = random.randint(5,20)                           ###64\n",
    "        first_layer.append(layer1)\n",
    "        layer2 = random.randint(5,20)                           ###32\n",
    "        sec_layer.append(layer2)\n",
    "        output1 = 2\n",
    "        model_layers[i].append(layer1)\n",
    "        model_layers[i].append(layer2)\n",
    "        if not (os.path.exists('layerdetails/models_' + str(id_num) + '/model_' + str(i))):\n",
    "            os.makedirs('layerdetails/models_' + str(id_num) + '/model_' + str(i))\n",
    "        with open('layerdetails/models_' + str(id_num) + '/model_' + str(i) + \"/layers.txt\",'w') as f:\n",
    "            f.write(str(layer1) + \" \" + str(layer2))\n",
    "        f.close\n",
    "        #np.savetxt(dirname + str(i) + '/layerdetails.txt',model_layers[i],delimiter=\"\\n\" )\n",
    "    else:\n",
    "        with open('layerdetails/models_' + str(id_num) + '/model_' + str(i) + \"/layers.txt\",'r') as r:\n",
    "            #print(r.readlines()[0])\n",
    "            layer = r.readlines()[0].split(\" \")\n",
    "            input1 = 10\n",
    "            layer1 = int(layer[0])\n",
    "            layer2 = int(layer[1])\n",
    "            output1 = 2\n",
    "            first_layer.append(layer1)\n",
    "            sec_layer.append(layer2)\n",
    "    model=Sequential()\n",
    "    model.add(QDense(layer1, input_shape=(input1,), name='fc1', kernel_quantizer=quantized_bits(8,0,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(8,0,alpha=1),\n",
    "                    kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ))\n",
    "    model.add(QActivation(activation=quantized_relu(8,0,use_stochastic_rounding=False), name='relu1'))\n",
    "    model.add(QDense(layer2, name='fc2',\n",
    "                    kernel_quantizer=quantized_bits(8,0,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(8,0,alpha=1),\n",
    "                    kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "    model.add(QActivation(activation=quantized_relu(8,0,use_stochastic_rounding=False), name='relu2'))\n",
    "    model.add(QDense(output1, name='output',\n",
    "                    kernel_quantizer=quantized_bits(8,0,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(8,0,alpha=1),\n",
    "                    kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "    model.add(Activation(activation='softmax', name='softmax'))\n",
    "    models.append(model)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "model_layers = np.array(model_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "612eaf18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "Train = False\n",
    "selector = 1\n",
    "for precision in range(8,1,-1):\n",
    "    \n",
    "    dirname = './models/models_' + str(id_num) + \"/prec_\" + str(precision) + \"/model_\"\n",
    "    for i in range(x,model_num,1):    \n",
    "        adam = Adam(lr=0.02)\n",
    "        if(Train):\n",
    "            pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(0.2, begin_step=2000, frequency=100)}\n",
    "            models[i] = prune.prune_low_magnitude(models[i], **pruning_params)\n",
    "            models[i].compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "            callbacks= all_callbacks( outputDir = 'arrythmia_classification_prune_new')\n",
    "            callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "\n",
    "    #         models[i].fit(X_train, Y_train, batch_size=1,\n",
    "    #                   epochs=15,validation_split=0.2, verbose=1, shuffle=True,\n",
    "    #                   callbacks = callbacks.callbacks);\n",
    "            models[i].fit(X_train,Y_train,batch_size=1024,epochs=10,\n",
    "                validation_split=0.25,\n",
    "                verbose=1,\n",
    "                shuffle=True,\n",
    "                callbacks=callbacks.callbacks,\n",
    "                )\n",
    "            models[i] = strip_pruning(models[i])\n",
    "            #model_save_quantized_weights(models[i], \"test_weights_new_\" + str(i) + \"_\" + str(id_num))\n",
    "            models[i].save(dirname + str(i) + '/KERAS_check_best_model.h5')\n",
    "\n",
    "                #stripped_model = strip_pruning(models[i])\n",
    "                #stripped_model.save('models/stripped_models' + str(id_num) + '/stripped_model'+str(i)+'/KERAS_check_best_model.h5')\n",
    "        for j in range(0,10,1):\n",
    "            loaded_models[i].save(dirname + str(i) + '/KERAS_check_best_model.h5')\n",
    "            config = hls4ml.utils.config_from_keras_model(loaded_models[i],granularity='name')\n",
    "            #config['Model']['Precision']='fixed<16,4>'\n",
    "            #config['LayerName']['fc1_input']['Precision']['result'] = 'fixed<8,2>'\n",
    "            #config['LayerName']['output']['Precision']['result'] = 'fixed<16,4>'\n",
    "            config['LayerName']['fc1_input']['Precision']['result'] = 'fixed<' + str(precision) + ',2>'\n",
    "            config['LayerName']['relu1']['Precision']['result'] = 'ap_ufixed<' + str(precision) + ',0,AP_RND_CONV,AP_SAT>'\n",
    "            config['LayerName']['relu2']['Precision']['result'] = 'ap_ufixed<' + str(precision) + ',0,AP_RND_CONV,AP_SAT>'\n",
    "\n",
    "            config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "            config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "            config['Model']['ReuseFactor'] = j + 1\n",
    "            #config['LayerName']['fc1']['Precision']['result'] = 'fixed<16,4>'\n",
    "            #config['LayerName']['fc2']['Precision']['result'] = 'fixed<16,4>'\n",
    "\n",
    "            hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "                loaded_models[i],hls_config = config,output_dir = dirname + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj',part = 'xc7z007s-clg225-2')\n",
    "            hls_model.compile()\n",
    "            os.system('cp -r build_prj_orig.tcl project_orig.tcl build_prj_orig_lut.tcl ' + dirname + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj')\n",
    "            os.system('cp init.sh init_lut.sh ' + dirname + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj')\n",
    "            start_dir = os.getcwd()\n",
    "            os.chdir(r'./models/models_'+ str(id_num) + \"/prec_\" + str(precision) + \"/model_\" + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj')\n",
    "            if selector:\n",
    "                os.system('bash init.sh')\n",
    "                os.system('rm init_lut.sh')\n",
    "            else:\n",
    "                os.system('rm init.sh')\n",
    "                os.system('bash init_lut.sh')\n",
    "            os.chdir(start_dir)        \n",
    "            if j==9:\n",
    "                     for num in range(j+2):\n",
    "                         os.system('rm -r ' + dirname +str(i) + '/reuse_' + str(num) + '/hls4ml_prj/myproject_prj/solution1/.autopilot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d606530b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selector = 1\n",
    "for precision in range (8,1,-1):\n",
    "    dirname = './models/models_' + str(id_num) + \"/prec_\" + str(precision) + \"/model_\"\n",
    "    for i in range(0,model_num,1):\n",
    "        for j in range(19,max_RF,10):\n",
    "            config = hls4ml.utils.config_from_keras_model(loaded_models[i],granularity='name')\n",
    "            config['LayerName']['fc1_input']['Precision']['result'] = 'fixed<' + str(precision) + ',2>'\n",
    "            config['LayerName']['relu1']['Precision']['result'] = 'ap_ufixed<' + str(precision) + ',0,AP_RND_CONV,AP_SAT>'\n",
    "            config['LayerName']['relu2']['Precision']['result'] = 'ap_ufixed<' + str(precision) + ',0,AP_RND_CONV,AP_SAT>'\n",
    "            #config['LayerName']['relu3']['Precision']['result'] = 'ap_ufixed<' + str(precision) + ',0,AP_RND_CONV,AP_SAT>'\n",
    "            \n",
    "            config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "            config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "            config['Model']['ReuseFactor'] = j + 1\n",
    "                #config['LayerName']['fc1']['Precision']['result'] = 'fixed<16,4>'\n",
    "                #config['LayerName']['fc2']['Precision']['result'] = 'fixed<16,4>'\n",
    "\n",
    "            hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "            loaded_models[i],hls_config = config,output_dir = dirname + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj',part = 'xc7z007s-clg225-2')\n",
    "            hls_model.compile()\n",
    "            os.system('cp -r build_prj_orig.tcl project_orig.tcl build_prj_orig_lut.tcl ' + dirname + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj')\n",
    "            os.system('cp init.sh init_lut.sh ' + dirname + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj')\n",
    "            start_dir = os.getcwd()\n",
    "            os.chdir(r'./models/models_'+ str(id_num) + \"/prec_\" + str(precision) + \"/model_\" + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj')\n",
    "            if selector:\n",
    "                os.system('bash init.sh')\n",
    "                os.system('rm init_lut.sh')\n",
    "            else:\n",
    "                os.system('rm init.sh')\n",
    "                os.system('bash init_lut.sh')\n",
    "            os.chdir(start_dir)\n",
    "            if j==99:\n",
    "                    for num in range(j + 2):\n",
    "                        os.system('rm -r ' + dirname + str(i) + '/reuse_' + str(num) + '/hls4ml_prj/myproject_prj/solution1/.autopilot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c329b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
