{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70887ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "seed=0\n",
    "np.random.seed(seed)\n",
    "\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "import tensorflow.compat.v1 as tf1\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "from qkeras.utils import model_save_quantized_weights, load_qmodel\n",
    "import hls4ml\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dbd84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./breast-cancer-wisconsin.csv', sep = ';')\n",
    "X = df.drop('Y', axis = 1).values\n",
    "y = df.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a0219dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "Y_reshaped = [[label] for label in y]\n",
    "Y_encoded = encoder.fit_transform(Y_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96092f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_encoded = Y_encoded.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d004507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y_encoded,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99aafd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler(feature_range=(0,0.9))\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de0aee",
   "metadata": {},
   "source": [
    "# Train for different precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35e196da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 20\n",
    "id_num = 0\n",
    "max_RF = 100\n",
    "precision = 8\n",
    "dirname = './models/models_' + str(id_num) + \"/prec_\" + str(precision) + \"/model_\"\n",
    "dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0d78843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "from qkeras.utils import model_save_quantized_weights, load_qmodel\n",
    "import hls4ml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c693ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "import qkeras.qtools.qtools_util\n",
    "import qkeras.estimate\n",
    "loaded_models = []\n",
    "for model_no in range(model_num):\n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    loaded_models.append(load_model(dirname + str(model_no) + '/KERAS_check_best_model.h5', custom_objects=co))\n",
    "#model = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d15ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready = True\n",
    "models = []\n",
    "first_layer = []\n",
    "sec_layer = []\n",
    "model_num = 20\n",
    "model_layers = [[] for x in range(model_num)]\n",
    "bits = 8\n",
    "int_bits = 0\n",
    "for i in range(model_num):\n",
    "    if ready:\n",
    "        input1 = 10\n",
    "        layer1 = random.randint(5,20)                           ###64\n",
    "        first_layer.append(layer1)\n",
    "        layer2 = random.randint(5,20)                           ###32\n",
    "        sec_layer.append(layer2)\n",
    "        output1 = 2\n",
    "        model_layers[i].append(layer1)\n",
    "        model_layers[i].append(layer2)\n",
    "        if not (os.path.exists('layerdetails/models_' + str(id_num) + '/model_' + str(i))):\n",
    "            os.makedirs('layerdetails/models_' + str(id_num) + '/model_' + str(i))\n",
    "        with open('layerdetails/models_' + str(id_num) + '/model_' + str(i) + \"/layers.txt\",'w') as f:\n",
    "            f.write(str(layer1) + \" \" + str(layer2))\n",
    "        f.close\n",
    "        #np.savetxt(dirname + str(i) + '/layerdetails.txt',model_layers[i],delimiter=\"\\n\" )\n",
    "    else:\n",
    "        with open('layerdetails/models_' + str(id_num) + '/model_' + str(i) + \"/layers.txt\",'r') as r:\n",
    "            #print(r.readlines()[0])\n",
    "            layer = r.readlines()[0].split(\" \")\n",
    "            input1 = 10\n",
    "            layer1 = int(layer[0])\n",
    "            layer2 = int(layer[1])\n",
    "            output1 = 2\n",
    "            first_layer.append(layer1)\n",
    "            sec_layer.append(layer2)\n",
    "    model=Sequential()\n",
    "    model.add(QDense(layer1, input_shape=(input1,), name='fc1', kernel_quantizer=quantized_bits(bits,int_bits,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(bits,int_bits,alpha=1),\n",
    "                    kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ))\n",
    "    model.add(QActivation(activation=quantized_relu(bits,int_bits,use_stochastic_rounding=False), name='relu1'))\n",
    "    model.add(QDense(layer2, name='fc2',\n",
    "                    kernel_quantizer=quantized_bits(bits,int_bits,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(bits,int_bits,alpha=1),\n",
    "                    kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "    model.add(QActivation(activation=quantized_relu(bits,int_bits,use_stochastic_rounding=False), name='relu2'))\n",
    "    model.add(QDense(output1, name='output',\n",
    "                    kernel_quantizer=quantized_bits(bits,int_bits,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(bits,int_bits,alpha=1),\n",
    "                    kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "    model.add(Activation(activation='softmax', name='softmax'))\n",
    "    models.append(model)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "model_layers = np.array(model_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "612eaf18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "Train = True\n",
    "selector = 1\n",
    "for precision in range(8,1,-1):\n",
    "    dirname = './models/models_' + str(id_num) + \"/prec_\" + str(precision) + \"/model_\"\n",
    "    for i in range(0,model_num,1):    \n",
    "        adam = Adam(lr=0.02)\n",
    "        if(Train):\n",
    "            loaded_models = models\n",
    "            pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(0.2, begin_step=2000, frequency=100)}\n",
    "            models[i] = prune.prune_low_magnitude(models[i], **pruning_params)\n",
    "            models[i].compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "            callbacks= all_callbacks( outputDir = 'arrythmia_classification_prune_new')\n",
    "            callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "\n",
    "    #         models[i].fit(X_train, Y_train, batch_size=1,\n",
    "    #                   epochs=15,validation_split=0.2, verbose=1, shuffle=True,\n",
    "    #                   callbacks = callbacks.callbacks);\n",
    "            models[i].fit(X_train,Y_train,batch_size=64,epochs=10,\n",
    "                validation_split=0.25,\n",
    "                verbose=1,\n",
    "                shuffle=True,\n",
    "                callbacks=callbacks.callbacks,\n",
    "                )\n",
    "            models[i] = strip_pruning(models[i])\n",
    "            #model_save_quantized_weights(models[i], \"test_weights_new_\" + str(i) + \"_\" + str(id_num))\n",
    "            models[i].save(dirname + str(i) + '/KERAS_check_best_model.h5')\n",
    "        rf_range = [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100]\n",
    "        for j in rf_range:\n",
    "            loaded_models[i].save(dirname + str(i) + '/KERAS_check_best_model.h5')\n",
    "            config = hls4ml.utils.config_from_keras_model(loaded_models[i],granularity='name')\n",
    "            #config['Model']['Precision']='fixed<16,4>'\n",
    "            #config['LayerName']['fc1_input']['Precision']['result'] = 'fixed<8,2>'\n",
    "            #config['LayerName']['output']['Precision']['result'] = 'fixed<16,4>'\n",
    "            config['LayerName']['fc1_input']['Precision']['result'] = 'fixed<' + str(precision) + ',2>'\n",
    "            config['LayerName']['relu1']['Precision']['result'] = 'ap_ufixed<' + str(precision) + ',0,AP_RND_CONV,AP_SAT>'\n",
    "            config['LayerName']['relu2']['Precision']['result'] = 'ap_ufixed<' + str(precision) + ',0,AP_RND_CONV,AP_SAT>'\n",
    "\n",
    "            config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "            config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "            config['Model']['ReuseFactor'] = j\n",
    "            #config['LayerName']['fc1']['Precision']['result'] = 'fixed<16,4>'\n",
    "            #config['LayerName']['fc2']['Precision']['result'] = 'fixed<16,4>'\n",
    "\n",
    "            hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "                loaded_models[i],hls_config = config,output_dir = dirname + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj',part = 'xc7z007s-clg225-2')\n",
    "            hls_model.compile()\n",
    "            os.system('cp -r build_prj_orig.tcl project_orig.tcl build_prj_orig_lut.tcl ' + dirname + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj')\n",
    "            os.system('cp init.sh init_lut.sh ' + dirname + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj')\n",
    "            start_dir = os.getcwd()\n",
    "            os.chdir(r'./models/models_'+ str(id_num) + \"/prec_\" + str(precision) + \"/model_\" + str(i) + '/reuse_' + str(j + 1) + '/hls4ml_prj')\n",
    "            if selector:\n",
    "                os.system('bash init.sh')\n",
    "                os.system('rm init_lut.sh')\n",
    "            else:\n",
    "                os.system('rm init.sh')\n",
    "                os.system('bash init_lut.sh')\n",
    "            os.chdir(start_dir)        \n",
    "            if j==9:\n",
    "                     for num in range(j+2):\n",
    "                         os.system('rm -r ' + dirname +str(i) + '/reuse_' + str(num) + '/hls4ml_prj/myproject_prj/solution1/.autopilot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c329b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
