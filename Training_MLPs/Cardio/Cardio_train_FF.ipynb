{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac052873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "seed=0\n",
    "np.random.seed(seed)\n",
    "\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "import tensorflow.compat.v1 as tf1\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "from qkeras.utils import model_save_quantized_weights, load_qmodel\n",
    "import hls4ml\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31565857",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_RF = 100\n",
    "id_num = 2\n",
    "precision = 8\n",
    "dirname = './models/models_' + str(id_num) + \"/prec_\" + str(precision) + \"/model_\"\n",
    "dirname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0845b43",
   "metadata": {},
   "source": [
    "## Preprocess data to train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c22a34dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset.csv', sep = ';')\n",
    "X = df.drop('Y', axis = 1).values\n",
    "y = df.Y\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(le.classes_)\n",
    "y = to_categorical(y, 3)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "ls=np.argmax(Y_test,axis=1)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b554d8f",
   "metadata": {},
   "source": [
    "Create Qkeras model and configure HLS models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "906bc2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = np.arange(3,23)\n",
    "model_num = 20\n",
    "\n",
    "models = []\n",
    "bits = 8\n",
    "int_bits = 0\n",
    "for i in range(model_num):\n",
    "    model=Sequential()\n",
    "    model.add(QDense(layer[i], input_shape=(21,), name='fc1', kernel_quantizer=quantized_bits(bits,int_bits,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(bits,int_bits,alpha=1),\n",
    "                    kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ))\n",
    "    model.add(QActivation(activation=quantized_relu(bits,int_bits,use_stochastic_rounding=False), name='relu1'))\n",
    "    model.add(QDense(3, name='output',\n",
    "                    kernel_quantizer=quantized_bits(bits,int_bits,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(bits,int_bits,alpha=1),\n",
    "                    kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "    model.add(Activation(activation='softmax', name='softmax'))\n",
    "    models.append(model)\n",
    "#model.layers[0].set_weights(wb1)\n",
    "#model.layers[2].set_weights(wb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5eb3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "import qkeras.qtools.qtools_util\n",
    "import qkeras.estimate\n",
    "loaded_models = []\n",
    "for model_no in range(model_num):\n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    loaded_models.append(load_model(dirname + str(model_no) + '/KERAS_check_best_model.h5', custom_objects=co))\n",
    "    qkeras.utils.get_model_sparsity(model_no)\n",
    "#model = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e7500f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "Train = True\n",
    "selector = 1\n",
    "for precision in range(8,1,-1):\n",
    "    dirname = './models/models_' + str(id_num) + \"/prec_\" + str(precision) + \"/model_\"\n",
    "    for i in range(0,model_num,1):    \n",
    "        adam = Adam(lr=0.02)\n",
    "        if(Train):\n",
    "            loaded_models = models\n",
    "            pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(0.2, begin_step=2000, frequency=100)}\n",
    "            loaded_models[i] = prune.prune_low_magnitude(loaded_models[i], **pruning_params)\n",
    "            loaded_models[i].compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "            callbacks= all_callbacks( outputDir = 'jet_tagging_new')\n",
    "            callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "            loaded_models[i].fit(X_train,Y_train,batch_size=64,epochs=10,\n",
    "                validation_split=0.25,\n",
    "                verbose=1,\n",
    "                shuffle=True,\n",
    "                callbacks=callbacks.callbacks,\n",
    "                )\n",
    "            loaded_models[i] = strip_pruning(models[i])\n",
    "            loaded_models[i].save(dirname + str(i) + '/KERAS_check_best_model.h5')\n",
    "\n",
    "                #stripped_model = strip_pruning(models[i])\n",
    "                #stripped_model.save('models/stripped_models' + str(id_num) + '/stripped_model'+str(i)+'/KERAS_check_best_model.h5')\n",
    "        rf_range = [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100]\n",
    "        for j in rf_range:\n",
    "            loaded_models[i].save(dirname + str(i) + '/KERAS_check_best_model.h5')\n",
    "            config = hls4ml.utils.config_from_keras_model(loaded_models[i],granularity='name')\n",
    "\n",
    "            config['LayerName']['fc1_input']['Precision']['result'] = 'fixed<' + str(precision) + ',2>'\n",
    "            config['LayerName']['relu1']['Precision']['result'] = 'ap_ufixed<' + str(precision) + ',0,AP_RND_CONV,AP_SAT>'\n",
    "            \n",
    "            config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "            config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "            config['Model']['ReuseFactor'] = j\n",
    "            #config['LayerName']['fc1']['Precision']['result'] = 'fixed<16,4>'\n",
    "            #config['LayerName']['fc2']['Precision']['result'] = 'fixed<16,4>'\n",
    "\n",
    "            hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "                loaded_models[i],hls_config = config,output_dir = dirname + str(i) + '/reuse_' + str(j) + '/hls4ml_prj',part = 'xc7z007s-clg225-2')\n",
    "            hls_model.compile()\n",
    "            os.system('cp -r build_prj_orig.tcl project_orig.tcl build_prj_orig_lut.tcl ' + dirname + str(i) + '/reuse_' + str(j) + '/hls4ml_prj')\n",
    "            os.system('cp init.sh init_lut.sh ' + dirname + str(i) + '/reuse_' + str(j) + '/hls4ml_prj')\n",
    "            start_dir = os.getcwd()\n",
    "            os.chdir(r'./models/models_'+ str(id_num) + \"/prec_\" + str(precision) + \"/model_\" + str(i) + '/reuse_' + str(j) + '/hls4ml_prj')\n",
    "            if selector:\n",
    "                os.system('bash init.sh')\n",
    "                os.system('rm init_lut.sh')\n",
    "            else:\n",
    "                os.system('rm init.sh')\n",
    "                os.system('bash init_lut.sh')\n",
    "            os.chdir(start_dir)        \n",
    "            if j==100:\n",
    "                     for num in range(j+2):\n",
    "                         os.system('rm -r ' + dirname +str(i) + '/reuse_' + str(num) + '/hls4ml_prj/myproject_prj/solution1/.autopilot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474acdde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
